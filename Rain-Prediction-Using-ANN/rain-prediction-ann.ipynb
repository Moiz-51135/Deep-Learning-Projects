{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1733506,"sourceType":"datasetVersion","datasetId":6012}],"dockerImageVersionId":30060,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom keras.layers import Dense, BatchNormalization, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\nfrom keras import callbacks\n\nnp.random.seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/weather-dataset-rattle-package/weatherAUS.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first of all let us evaluate the target and find out if our data is imbalanced or not\ncols= [\"#C2C4E2\",\"#EED4E5\"]\nsns.countplot(x= data[\"RainTomorrow\"], palette= cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation amongst numeric attributes\ncorrmat = data.corr()\ncmap = sns.diverging_palette(260,-10,s=50, l=75, n=6, as_cmap=True)\nplt.subplots(figsize=(18,18))\nsns.heatmap(corrmat,cmap= cmap,annot=True, square=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Parsing datetime\n#exploring the length of date objects\nlengths = data[\"Date\"].str.len()\nlengths.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There don't seem to be any error in dates so parsing values into datetime\ndata['Date']= pd.to_datetime(data[\"Date\"])\n#Creating a collumn of year\ndata['year'] = data.Date.dt.year\n\n# function to encode datetime into cyclic parameters. \n#As I am planning to use this data in a neural network I prefer the months and days in a cyclic continuous feature. \n\ndef encode(data, col, max_val):\n    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n    return data\n\ndata['month'] = data.Date.dt.month\ndata = encode(data, 'month', 12)\n\ndata['day'] = data.Date.dt.day\ndata = encode(data, 'day', 31)\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roughly a year's span section \nsection = data[:360] \ntm = section[\"day\"].plot(color=\"#C2C4E2\")\ntm.set_title(\"Distribution Of Days Over Year\")\ntm.set_ylabel(\"Days In month\")\ntm.set_xlabel(\"Days In Year\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the \"year\" attribute of data repeats. However in this for the true cyclic nature is not presented in a continuous manner. Splitting months and days into Sine and cosine combination provides the cyclical continuous feature. This can be used as input features to ANN. ","metadata":{}},{"cell_type":"code","source":"cyclic_month = sns.scatterplot(x=\"month_sin\",y=\"month_cos\",data=data, color=\"#C2C4E2\")\ncyclic_month.set_title(\"Cyclic Encoding of Month\")\ncyclic_month.set_ylabel(\"Cosine Encoded Months\")\ncyclic_month.set_xlabel(\"Sine Encoded Months\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cyclic_day = sns.scatterplot(x='day_sin',y='day_cos',data=data, color=\"#C2C4E2\")\ncyclic_day.set_title(\"Cyclic Encoding of Day\")\ncyclic_day.set_ylabel(\"Cosine Encoded Day\")\ncyclic_day.set_xlabel(\"Sine Encoded Day\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get list of categorical variables\ns = (data.dtypes == \"object\")\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values in categorical variables\n\nfor i in object_cols:\n    print(i, data[i].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values with mode of the column in value\n\nfor i in object_cols:\n    data[i].fillna(data[i].mode()[0], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Numerical variables**\n\n* Filling missing values with median of the column value","metadata":{}},{"cell_type":"code","source":"# Get list of neumeric variables\nt = (data.dtypes == \"float64\")\nnum_cols = list(t[t].index)\n\nprint(\"Neumeric variables:\")\nprint(num_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values in numeric variables\n\nfor i in num_cols:\n    print(i, data[i].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values with median of the column in value\n\nfor i in num_cols:\n    data[i].fillna(data[i].median(), inplace=True)\n    \ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting a lineplot rainfall over years\nplt.figure(figsize=(12,8))\nTime_series=sns.lineplot(x=data['Date'].dt.year,y=\"Rainfall\",data=data,color=\"#C2C4E2\")\nTime_series.set_title(\"Rainfall Over Years\")\nTime_series.set_ylabel(\"Rainfall\")\nTime_series.set_xlabel(\"Years\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evauating Wind gust speed over years\ncolours = [\"#D0DBEE\", \"#C2C4E2\", \"#EED4E5\", \"#D1E6DC\", \"#BDE2E2\"]\nplt.figure(figsize=(12,8))\nDays_of_week=sns.barplot(x=data['Date'].dt.year,y=\"WindGustSpeed\",data=data, ci =None,palette = colours)\nDays_of_week.set_title(\"Wind Gust Speed Over Years\")\nDays_of_week.set_ylabel(\"WindGustSpeed\")\nDays_of_week.set_xlabel(\"Year\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Label encoding the catagorical varable**","metadata":{}},{"cell_type":"code","source":"# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor i in object_cols:\n    data[i] = label_encoder.fit_transform(data[i])\n    \ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepairing attributes of scale data\n\nfeatures = data.drop(['RainTomorrow', 'Date','day', 'month'], axis=1) # dropping target and extra columns\n\ntarget = data['RainTomorrow']\n\n#Set up a standard scaler for the features\ncol_names = list(features.columns)\ns_scaler = preprocessing.StandardScaler()\nfeatures = s_scaler.fit_transform(features)\nfeatures = pd.DataFrame(features, columns=col_names) \n\nfeatures.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Detecting outliers\n#looking at the scaled features\ncolours = [\"#D0DBEE\", \"#C2C4E2\", \"#EED4E5\", \"#D1E6DC\", \"#BDE2E2\"]\nplt.figure(figsize=(20,10))\nsns.boxenplot(data = features,palette = colours)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#full data for \nfeatures[\"RainTomorrow\"] = target\n\n#Dropping with outlier\n\nfeatures = features[(features[\"MinTemp\"]<2.3)&(features[\"MinTemp\"]>-2.3)]\nfeatures = features[(features[\"MaxTemp\"]<2.3)&(features[\"MaxTemp\"]>-2)]\nfeatures = features[(features[\"Rainfall\"]<4.5)]\nfeatures = features[(features[\"Evaporation\"]<2.8)]\nfeatures = features[(features[\"Sunshine\"]<2.1)]\nfeatures = features[(features[\"WindGustSpeed\"]<4)&(features[\"WindGustSpeed\"]>-4)]\nfeatures = features[(features[\"WindSpeed9am\"]<4)]\nfeatures = features[(features[\"WindSpeed3pm\"]<2.5)]\nfeatures = features[(features[\"Humidity9am\"]>-3)]\nfeatures = features[(features[\"Humidity3pm\"]>-2.2)]\nfeatures = features[(features[\"Pressure9am\"]< 2)&(features[\"Pressure9am\"]>-2.7)]\nfeatures = features[(features[\"Pressure3pm\"]< 2)&(features[\"Pressure3pm\"]>-2.7)]\nfeatures = features[(features[\"Cloud9am\"]<1.8)]\nfeatures = features[(features[\"Cloud3pm\"]<2)]\nfeatures = features[(features[\"Temp9am\"]<2.3)&(features[\"Temp9am\"]>-2)]\nfeatures = features[(features[\"Temp3pm\"]<2.3)&(features[\"Temp3pm\"]>-2)]\n\n\nfeatures.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#looking at the scaled features without outliers\n\nplt.figure(figsize=(20,10))\nsns.boxenplot(data = features,palette = colours)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks Good. Up next is building artificial neural network.","metadata":{}},{"cell_type":"code","source":"X = features.drop([\"RainTomorrow\"], axis=1)\ny = features[\"RainTomorrow\"]\n\n# Splitting test and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Early stopping\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\n# Initialising the NN\nmodel = Sequential()\n\n# layers\n\nmodel.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 26))\nmodel.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nopt = Adam(learning_rate=0.00009)\nmodel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Train the ANN\nhistory = model.fit(X_train, y_train, batch_size = 32, epochs = 150, callbacks=[early_stopping], validation_split=0.2)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting training and validation loss over epochs","metadata":{}},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['loss']], \"#BDE2E2\", label='Training loss')\nplt.plot(history_df.loc[:, ['val_loss']],\"#C2C4E2\", label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=\"best\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting training and validation accuracy over epochs","metadata":{}},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['accuracy']], \"#BDE2E2\", label='Training accuracy')\nplt.plot(history_df.loc[:, ['val_accuracy']], \"#C2C4E2\", label='Validation accuracy')\n\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the test set results\ny_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix\ncmap1 = sns.diverging_palette(260,-10,s=50, l=75, n=5, as_cmap=True)\nplt.subplots(figsize=(12,8))\ncf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}